{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='../../data/train'\n",
    "train_df= pd.read_csv(os.path.join(data_path,'train_ratings.csv'))\n",
    "train_df=train_df.drop(columns='time')\n",
    "train_df['rating']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_negative_items(data, seed, num_negative):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - data (DataFrame): 전체 사용자-아이템 상호작용 데이터\n",
    "    - seed (int): 랜덤 시드 값 (재현성을 위해 사용)\n",
    "    - num_negative (int): 생성할 부정 샘플의 수\n",
    "\n",
    "    Returns:\n",
    "    - data_total (DataFrame): 부정 샘플이 포함된 전체 데이터프레임\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)  # 난수 생성기를 시드와 함께 초기화(재현성 보장)\n",
    "    items = set(data['item'].unique())  # 전체 아이템 집합\n",
    "    total = []\n",
    "\n",
    "    for user, group in data.groupby('user'):\n",
    "        interacted_items = set(group['item'])  # 사용자가 이미 본 아이템 추출\n",
    "        non_interacted_items = list(items - interacted_items)  # 사용자가 보지 않은 아이템 추출\n",
    "\n",
    "        if len(non_interacted_items) < num_negative:\n",
    "            sampled_items = non_interacted_items\n",
    "        else:\n",
    "            sampled_items = rng.choice(non_interacted_items, size=num_negative, replace=False)\n",
    "\n",
    "        # 부정 샘플 데이터프레임 생성\n",
    "        negative_samples = pd.DataFrame({\n",
    "            'user': [user] * len(sampled_items),\n",
    "            'item': sampled_items,\n",
    "            'rating': [0] * len(sampled_items)  # 부정 샘플은 rating=0\n",
    "        })\n",
    "\n",
    "        total.append(negative_samples)\n",
    "\n",
    "    # 원본 데이터와 부정 샘플을 합침\n",
    "    data_total = pd.concat([data] + total, ignore_index=True)\n",
    "\n",
    "    return data_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_total = sample_negative_items(train_df, 42, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6722471"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='../../data/train'\n",
    "genres_df= pd.read_csv(os.path.join(data_path,'genres.tsv'),sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre2idx={}\n",
    "for idx,genre in enumerate(set(genres_df['genre'])):\n",
    "    genre2idx[genre]=idx+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_df['genre']=genres_df['genre'].apply(lambda x: [genre2idx[x]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_lst=[]\n",
    "group_lst=[]\n",
    "for item,group in genres_df.groupby('item',sort=False):\n",
    "    item_lst.append(item)\n",
    "    group_lst.append(group['genre'].sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=pd.DataFrame(item_lst,columns=['item'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = pd.DataFrame({'genre': group_lst})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_df=pd.concat([A,B],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_total=pd.merge(data_total,genre_df,how='left',on='item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4643</td>\n",
       "      <td>1</td>\n",
       "      <td>[10, 3, 12, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>[10, 3, 15, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>531</td>\n",
       "      <td>1</td>\n",
       "      <td>[18, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>616</td>\n",
       "      <td>1</td>\n",
       "      <td>[11, 18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>2140</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6722466</th>\n",
       "      <td>138493</td>\n",
       "      <td>1840</td>\n",
       "      <td>0</td>\n",
       "      <td>[12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6722467</th>\n",
       "      <td>138493</td>\n",
       "      <td>2533</td>\n",
       "      <td>0</td>\n",
       "      <td>[10, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6722468</th>\n",
       "      <td>138493</td>\n",
       "      <td>91690</td>\n",
       "      <td>0</td>\n",
       "      <td>[9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6722469</th>\n",
       "      <td>138493</td>\n",
       "      <td>8879</td>\n",
       "      <td>0</td>\n",
       "      <td>[15, 4, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6722470</th>\n",
       "      <td>138493</td>\n",
       "      <td>73266</td>\n",
       "      <td>0</td>\n",
       "      <td>[9, 12, 8]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6722471 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           user   item  rating            genre\n",
       "0            11   4643       1  [10, 3, 12, 14]\n",
       "1            11    170       1   [10, 3, 15, 2]\n",
       "2            11    531       1         [18, 12]\n",
       "3            11    616       1         [11, 18]\n",
       "4            11   2140       1          [3, 13]\n",
       "...         ...    ...     ...              ...\n",
       "6722466  138493   1840       0             [12]\n",
       "6722467  138493   2533       0         [10, 14]\n",
       "6722468  138493  91690       0              [9]\n",
       "6722469  138493   8879       0       [15, 4, 2]\n",
       "6722470  138493  73266       0       [9, 12, 8]\n",
       "\n",
       "[6722471 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "item2idx={}\n",
    "user2idx={}\n",
    "idx2item={}\n",
    "idx2user={}\n",
    "for idx,item in enumerate(np.sort(data_total['item'].unique())):\n",
    "    item2idx[item]=idx\n",
    "    idx2item[idx]=item\n",
    "for idx,user in enumerate(np.sort(data_total['user'].unique())):\n",
    "    user2idx[user]=idx\n",
    "    idx2user[idx]=user\n",
    "data_total['user']=data_total['user'].apply(lambda x: user2idx[x])\n",
    "data_total['item']=data_total['item'].apply(lambda x: item2idx[x])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCF (deep) class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class NCF_GM(nn.Module):\n",
    "    def __init__(self, num_user, num_item, num_genres, embedding_dim=32, side_emb_dim=16, dropout_rate=0.2):\n",
    "        super(NCF_GM, self).__init__()\n",
    "        \n",
    "        # Separate embeddings for NCF\n",
    "        self.ncf_user_embedding = nn.Embedding(num_user, embedding_dim)\n",
    "        self.ncf_item_embedding = nn.Embedding(num_item, embedding_dim)\n",
    "        self.genre_embedding = nn.Embedding(num_genres, side_emb_dim, padding_idx=0)\n",
    "        \n",
    "        # Separate embeddings for GM\n",
    "        self.gm_user_embedding = nn.Embedding(num_user, embedding_dim)\n",
    "        self.gm_item_embedding = nn.Embedding(num_item, embedding_dim)\n",
    "        \n",
    "        # Fully connected layers for NCF\n",
    "        self.fc1 = nn.Linear(2 * embedding_dim + side_emb_dim, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        \n",
    "        # Activation and dropout\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, user_ids, item_ids, genres):\n",
    "        # ===== GM Component =====\n",
    "        # Embed users and items for GM\n",
    "        gm_user_emb = self.gm_user_embedding(user_ids)  # Shape: (batch_size, embedding_dim)\n",
    "        gm_item_emb = self.gm_item_embedding(item_ids)  # Shape: (batch_size, embedding_dim)\n",
    "        \n",
    "        # Compute the interaction (dot product or generalized interaction)\n",
    "        gm_output = torch.sum(gm_user_emb * gm_item_emb, dim=1, keepdim=True)  # Shape: (batch_size, 1)\n",
    "\n",
    "        # ===== NCF Component =====\n",
    "        # Embed users and items for NCF\n",
    "        ncf_user_emb = self.ncf_user_embedding(user_ids)  # Shape: (batch_size, embedding_dim)\n",
    "        ncf_item_emb = self.ncf_item_embedding(item_ids)  # Shape: (batch_size, embedding_dim)\n",
    "        \n",
    "        # Embed genres and aggregate (mean)\n",
    "        genre_emb = self.genre_embedding(genres)  # Shape: (batch_size, num_genres, side_emb_dim)\n",
    "        genre_emb = genre_emb.mean(dim=1)  # Shape: (batch_size, side_emb_dim)\n",
    "\n",
    "        # Concatenate embeddings\n",
    "        ncf_input = torch.cat([ncf_user_emb, ncf_item_emb, genre_emb], dim=-1)  # Shape: (batch_size, 2*embedding_dim + side_emb_dim)\n",
    "        \n",
    "        # Pass through MLP layers\n",
    "        x = self.relu(self.bn1(self.fc1(ncf_input)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        ncf_output = self.fc4(x)  # Shape: (batch_size, 1)\n",
    "\n",
    "        # ===== Combine GM and NCF Outputs =====\n",
    "        # Combine GM and NCF predictions\n",
    "        output = torch.sigmoid(gm_output + ncf_output)  # Combine and apply sigmoid activation\n",
    "        \n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCF DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class RecommendationDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (pd.DataFrame): A pandas DataFrame containing user, item, rating, and genre columns.\n",
    "        \"\"\"\n",
    "        self.user_ids = torch.tensor(data['user'].values, dtype=torch.long)\n",
    "        self.item_ids = torch.tensor(data['item'].values, dtype=torch.long)\n",
    "        self.ratings = torch.tensor(data['rating'].values, dtype=torch.float32)\n",
    "        self.genres = data['genre'].apply(lambda x: torch.tensor(x, dtype=torch.long)).tolist()  # List of tensors\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'user_id': self.user_ids[idx],\n",
    "            'item_id': self.item_ids[idx],\n",
    "            'rating': self.ratings[idx],\n",
    "            'genre': self.genres[idx]  # A tensor of genre indices\n",
    "        }\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCF DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to pad genres and create a batch.\n",
    "    Args:\n",
    "        batch (list of dict): List of samples from the dataset.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A batch with padded genres.\n",
    "    \"\"\"\n",
    "    user_ids = torch.stack([sample['user_id'] for sample in batch])\n",
    "    item_ids = torch.stack([sample['item_id'] for sample in batch])\n",
    "    ratings = torch.stack([sample['rating'] for sample in batch])\n",
    "\n",
    "    # Pad the genre sequences\n",
    "    genres = [sample['genre'] for sample in batch]  # List of genre tensors\n",
    "    padded_genres = pad_sequence(genres, batch_first=True, padding_value=0)  # Padding with 0\n",
    "\n",
    "    return {\n",
    "        'user_id': user_ids,\n",
    "        'item_id': item_ids,\n",
    "        'rating': ratings,\n",
    "        'genre': padded_genres\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(genre2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----data loading------\n",
      "---model----\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'NCF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m side_emb_dim \u001b[39m=\u001b[39m \u001b[39m16\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m---model----\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m model \u001b[39m=\u001b[39m NCF(num_user\u001b[39m=\u001b[39mnum_users, num_item\u001b[39m=\u001b[39mnum_items, genre_item\u001b[39m=\u001b[39mnum_genres, \n\u001b[1;32m     20\u001b[0m             embedding_dim\u001b[39m=\u001b[39membedding_dim, side_emb_dim\u001b[39m=\u001b[39mside_emb_dim)\n\u001b[1;32m     22\u001b[0m \u001b[39m# Define loss and optimizer\u001b[39;00m\n\u001b[1;32m     23\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mBCELoss()  \u001b[39m# Binary Cross-Entropy Loss for implicit feedback\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NCF' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assume the dataset and model are defined\n",
    "print('-----data loading------')\n",
    "dataset = RecommendationDataset(data_total)  # Your dataset\n",
    "dataloader = DataLoader(dataset, batch_size=1024, shuffle=True, collate_fn=collate_fn, num_workers=4)\n",
    "\n",
    "# Define the model\n",
    "num_users = data_total['user'].nunique()\n",
    "num_items = data_total['item'].nunique()\n",
    "num_genres = len(genre2idx) +1   # Example: total number of unique genres + padding 0\n",
    "embedding_dim = 32\n",
    "side_emb_dim = 16\n",
    "print('---model----')\n",
    "model = NCF_GM(num_user=num_users, num_item=num_items, genre_item=num_genres, \n",
    "            embedding_dim=embedding_dim, side_emb_dim=side_emb_dim)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for implicit feedback\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "print('----train----')\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in tqdm(dataloader):\n",
    "        # Move data to the same device as the model\n",
    "        user_ids = batch['user_id'].to(device)\n",
    "        item_ids = batch['item_id'].to(device)\n",
    "        ratings = batch['rating'].to(device)  # Target values (1 for positive interaction, 0 for negative)\n",
    "        genres = batch['genre'].to(device)   # Padded genre indices\n",
    "    \n",
    "        # Forward pass\n",
    "        outputs = model(user_ids, item_ids, genres).squeeze()  # Predicted scores (sigmoid output)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, ratings)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "        loss.backward()        # Compute gradients\n",
    "        optimizer.step()       # Update weights\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_df = data_total[data_total['rating'] == 0]\n",
    "prediction_dataset = RecommendationDataset(negative_df)\n",
    "prediction_loader = DataLoader(prediction_dataset, batch_size=1024, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for user_id in tqdm(data_total['user'].unique()):\n",
    "        # 유저가 본 영화 제외\n",
    "        seen_items = set(data_total[data_total['user'] == user_id]['item'])\n",
    "        all_items = set(data_total['item'].unique())\n",
    "        unseen_items = list(all_items - seen_items)\n",
    "        \n",
    "        # 안본 영화 리스트 만들어놓기기\n",
    "        predict_df = pd.DataFrame({\n",
    "            'user': [user_id] * len(unseen_items),\n",
    "            'item': unseen_items,\n",
    "            'rating': [0] * len(unseen_items)  # Dummy ratings\n",
    "        })\n",
    "        \n",
    "        # 장르 merge\n",
    "        predict_df = pd.merge(predict_df, genre_df, how='left', on='item')\n",
    "        \n",
    "        # 만약 nan값 있을 경우 빈 리스트로 대체(없을거지만 혹시나해서)\n",
    "        predict_df['genre'] = predict_df['genre'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "        \n",
    "        # dataset, loader 만들기\n",
    "        prediction_dataset = RecommendationDataset(predict_df)\n",
    "        prediction_loader = DataLoader(prediction_dataset, batch_size=1024, collate_fn=collate_fn)\n",
    "        \n",
    "        user_predictions = []\n",
    "        for batch in prediction_loader:\n",
    "            # device에 몽땅 올려놓기\n",
    "            user_ids = batch['user_id'].to(device)\n",
    "            item_ids = batch['item_id'].to(device)\n",
    "            genres = batch['genre'].to(device)\n",
    "            \n",
    "            # 여기서 예측함\n",
    "            outputs = model(user_ids, item_ids, genres).squeeze()  # score가 생김\n",
    "            \n",
    "            if outputs.dim() == 0:  # output이 scalar인 경우 예외처리(batch size랑 유저 사이즈가 1차이날때 에러생기는거같음)\n",
    "                outputs = outputs.unsqueeze(0)\n",
    "            \n",
    "            user_predictions.extend(zip(item_ids.cpu().numpy(), outputs.cpu().numpy()))\n",
    "        \n",
    "        # 상위 10개 뽑아내서 유저에 붙이기\n",
    "        user_predictions = sorted(user_predictions, key=lambda x: x[1], reverse=True)[:10]\n",
    "        predictions.extend([(user_id, item_id, score) for item_id, score in user_predictions])\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions, columns=['user', 'item', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df[predictions_df['user']==0].sort_values(by='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_lst = predictions_df['user'].tolist()\n",
    "item_lst = predictions_df['item'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_user_lst = list(map(lambda x: idx2user[x], user_lst))\n",
    "mapped_item_lst = list(map(lambda x :idx2item[x],item_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(mapped_user_lst, mapped_item_lst)), columns=['user', 'item'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
